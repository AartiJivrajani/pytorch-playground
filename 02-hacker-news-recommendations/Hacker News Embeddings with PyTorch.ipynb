{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts: 989\n",
      "Users: 17684\n",
      "Total vectors: 18673\n",
      "Comments: 170360\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from random import random, shuffle\n",
    "from collections import defaultdict\n",
    "\n",
    "post_comments = []\n",
    "posts = set()\n",
    "with open(\"/Users/mtrencseni/Downloads/post_comments_1000.csv\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        post_comments.append(row)\n",
    "        posts.add(row[0])\n",
    "\n",
    "id_to_title = {}\n",
    "title_to_id = {}\n",
    "with open(\"/Users/mtrencseni/Downloads/top_1000_posts.csv\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        id_to_title[row[0]] = row[2]\n",
    "        title_to_id[row[2]] = row[0]\n",
    "\n",
    "print('Posts: %d' % len(posts))\n",
    "users = list(set([row[1] for row in post_comments]))\n",
    "print('Users: %d' % len(users))\n",
    "num_vectors = len(posts) + len(users)\n",
    "print('Total vectors: %d' % num_vectors)\n",
    "print('Comments: %d' % len(post_comments))\n",
    "post_lookup = {}\n",
    "idx = 0\n",
    "for post in posts:\n",
    "    post_lookup[post] = idx\n",
    "    idx += 1\n",
    "user_lookup = {}\n",
    "min_user_idx = idx\n",
    "for user in users:\n",
    "    user_lookup[user] = idx\n",
    "    idx += 1\n",
    "idx_list = [[post_lookup[post], user_lookup[user]] for [post, user] in post_comments]\n",
    "idx_user_posts = defaultdict(lambda: set())\n",
    "for [post_idx, user_idx] in idx_list:\n",
    "    idx_user_posts[user_idx].add(post_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: loss = 1.016\n",
      "0: loss = 1.009\n",
      "1: loss = 0.967\n",
      "2: loss = 0.939\n",
      "3: loss = 0.916\n",
      "4: loss = 0.891\n",
      "5: loss = 0.850\n",
      "6: loss = 0.825\n",
      "7: loss = 0.791\n",
      "8: loss = 0.770\n",
      "9: loss = 0.740\n",
      "10: loss = 0.701\n",
      "11: loss = 0.709\n",
      "12: loss = 0.709\n",
      "13: loss = 0.701\n",
      "14: loss = 0.668\n",
      "15: loss = 0.671\n",
      "16: loss = 0.670\n",
      "17: loss = 0.686\n",
      "18: loss = 0.666\n",
      "19: loss = 0.668\n",
      "20: loss = 0.643\n",
      "21: loss = 0.664\n",
      "22: loss = 0.644\n",
      "23: loss = 0.644\n",
      "24: loss = 0.612\n",
      "25: loss = 0.624\n",
      "26: loss = 0.652\n",
      "27: loss = 0.641\n",
      "28: loss = 0.655\n",
      "29: loss = 0.606\n",
      "30: loss = 0.639\n",
      "31: loss = 0.642\n",
      "32: loss = 0.619\n",
      "33: loss = 0.598\n",
      "34: loss = 0.618\n",
      "35: loss = 0.604\n",
      "36: loss = 0.635\n",
      "37: loss = 0.639\n",
      "38: loss = 0.626\n",
      "39: loss = 0.624\n",
      "40: loss = 0.630\n",
      "41: loss = 0.634\n",
      "42: loss = 0.631\n",
      "43: loss = 0.617\n",
      "44: loss = 0.620\n",
      "45: loss = 0.618\n",
      "46: loss = 0.602\n",
      "47: loss = 0.610\n",
      "48: loss = 0.619\n",
      "49: loss = 0.633\n",
      "0.319 vs -1.000\n",
      "0.395 vs 1.000\n",
      "0.226 vs -1.000\n",
      "-0.232 vs -1.000\n",
      "0.537 vs 1.000\n",
      "0.179 vs -1.000\n",
      "-0.020 vs 1.000\n",
      "0.392 vs 1.000\n",
      "0.141 vs 1.000\n",
      "-0.096 vs -1.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def build_minibatch(num_positives, num_negatives):\n",
    "    minibatch = []\n",
    "    for _ in range(num_positives):\n",
    "        which = int(len(idx_list) * random())\n",
    "        minibatch.append(idx_list[which] + [1])\n",
    "    for _ in range(num_negatives):\n",
    "        while True:\n",
    "            post = int(len(posts) * random())\n",
    "            user = min_user_idx + int(len(users) * random())\n",
    "            if post not in idx_user_posts[user]:\n",
    "                break\n",
    "        minibatch.append([post, user] + [-1])\n",
    "    shuffle(minibatch)\n",
    "    return minibatch\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, num_vectors, embedding_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_vectors, embedding_dim, max_norm=1.0)\n",
    "    def forward(self, input):\n",
    "        t1 = self.embedding(torch.LongTensor([v[0] for v in input]))\n",
    "        t2 = self.embedding(torch.LongTensor([v[1] for v in input]))\n",
    "        dot_products = torch.bmm(\n",
    "            t1.contiguous().view(len(input), 1, self.embedding.embedding_dim),\n",
    "            t2.contiguous().view(len(input), self.embedding.embedding_dim, 1)\n",
    "        )\n",
    "        return dot_products.contiguous().view(len(input))\n",
    "\n",
    "embedding_dim = 50\n",
    "model = Model(num_vectors, embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_function = torch.nn.MSELoss(reduction='mean')\n",
    "num_epochs = 50\n",
    "num_positives = 500\n",
    "num_negatives = 500\n",
    "minibatch_size = num_positives + num_negatives\n",
    "num_steps_per_epoch = int(len(post_comments) / num_positives)\n",
    "for i in range(num_epochs):\n",
    "    for j in range(num_steps_per_epoch):\n",
    "        optimizer.zero_grad()\n",
    "        minibatch = build_minibatch(num_positives, num_negatives)\n",
    "        y = model.forward(minibatch)\n",
    "        target = torch.FloatTensor([v[2] for v in minibatch])\n",
    "        loss = loss_function(y, target)\n",
    "        if i == 0 and j == 0:\n",
    "            print('r: loss = %.3f' % float(loss))\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "    print('%s: loss = %.3f' % (i, float(loss)))\n",
    "\n",
    "# print out some samples to see how good the fit is\n",
    "minibatch = build_minibatch(5, 5)\n",
    "y = model.forward(minibatch)\n",
    "target = torch.FloatTensor([v[2] for v in minibatch])\n",
    "for i in range(5+5):\n",
    "    print('%.3f vs %.3f' % (float(y[i]), float(target[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts similar to: Self-driving Uber car kills Arizona woman crossing street\n",
      "[0.890119731426239, 'https://news.ycombinator.com/item?id=16643056', 'Tempe Police Release Video of Uber Accident']\n",
      "[0.6932501792907715, 'https://news.ycombinator.com/item?id=16629673', 'Police Say Video Shows Woman Stepped Suddenly in Front of Self-Driving Uber']\n",
      "[0.6842777729034424, 'https://news.ycombinator.com/item?id=16761602', 'Tesla crash in September showed similarities to fatal Mountain View accident']\n",
      "\n",
      "Posts similar to: Ask HN: Who is hiring? (May 2018)\n",
      "[0.9896665215492249, 'https://news.ycombinator.com/item?id=16735011', 'Ask HN: Who is hiring? (April 2018)']\n",
      "[0.9825029373168945, 'https://news.ycombinator.com/item?id=17205865', 'Ask HN: Who is hiring? (June 2018)']\n",
      "[0.9820041656494141, 'https://news.ycombinator.com/item?id=18113144', 'Ask HN: Who is hiring? (October 2018)']\n",
      "\n",
      "Posts similar to: Conversations with a six-year-old on functional programming\n",
      "[0.7625867128372192, 'https://news.ycombinator.com/item?id=17036497', 'Common Lisp homepage']\n",
      "[0.6766821146011353, 'https://news.ycombinator.com/item?id=16884067', 'Towards Scala 3']\n",
      "[0.6692118644714355, 'https://news.ycombinator.com/item?id=17079952', 'JavaScript is Good, Actually']\n",
      "\n",
      "Posts similar to: You probably don't need AI/ML. You can make do with well written SQL scripts\n",
      "[0.6606734991073608, 'https://news.ycombinator.com/item?id=16847781', 'Time to rebuild the web?']\n",
      "[0.6535421013832092, 'https://news.ycombinator.com/item?id=16688521', 'Oracle Wins Revival of Billion-Dollar Case Against Google']\n",
      "[0.6232326626777649, 'https://news.ycombinator.com/item?id=16959188', 'IBM is not doing \"cognitive computing\" with Watson (2016)']\n",
      "\n",
      "Posts similar to: Bitcoin has little shot at ever being a major global currency\n",
      "[0.7136103510856628, 'https://news.ycombinator.com/item?id=16267428', 'U.S. Regulators to Subpoena Crypto Exchange Bitfinex, Tether']\n",
      "[0.7117798328399658, 'https://news.ycombinator.com/item?id=16115240', 'Buffett Says Stock Ownership Became More Attractive With Tax Cut']\n",
      "[0.7073562741279602, 'https://news.ycombinator.com/item?id=16107597', 'Building for the Blockchain']\n",
      "\n",
      "Posts similar to: 2018 MacBook Pro Review\n",
      "[0.7584781646728516, 'https://news.ycombinator.com/item?id=17231120', 'Apple introduces macOS Mojave']\n",
      "[0.7567641735076904, 'https://news.ycombinator.com/item?id=16766129', 'Appleâ€™s 2019 Mac Pro will be shaped by workflows']\n",
      "[0.7516911625862122, 'https://news.ycombinator.com/item?id=17554902', 'MacBook Pro with i9 chip is throttled due to thermal issues, claims YouTuber']\n",
      "\n",
      "Posts recommended for: Maro\n",
      "[0.585645318031311, 'https://news.ycombinator.com/item?id=16411662', \"Ask HN: Is it 'normal' to struggle so hard with work?\"]\n",
      "[0.4935797452926636, 'https://news.ycombinator.com/item?id=16409768', 'Ask HN: What has HN given you?']\n",
      "[0.4779208302497864, 'https://news.ycombinator.com/item?id=16153840', 'Google Memory Loss']\n",
      "[0.4611961841583252, 'https://news.ycombinator.com/item?id=16424954', 'Why is it hard to make friends over 30? (2012)']\n",
      "[0.4569213092327118, 'https://news.ycombinator.com/item?id=17039144', 'Microsoft Turned Consumers Against the Skype Brand']\n",
      "[0.45563530921936035, 'https://news.ycombinator.com/item?id=16465762', \"Ask HN: I'm writing a book about white-collar drug use, including tech sector\"]\n",
      "[0.4458724856376648, 'https://news.ycombinator.com/item?id=16483241', 'Why I Quit Google to Work for Myself']\n",
      "[0.4188252091407776, 'https://news.ycombinator.com/item?id=16200007', 'The Death of Microservice Madness in 2018']\n",
      "[0.4065665006637573, 'https://news.ycombinator.com/item?id=16724962', 'Facebook Secretly Saved Videos Users Deleted']\n",
      "[0.40470829606056213, 'https://news.ycombinator.com/item?id=16146950', 'CES Was Full of Useless Robots and Machines That Donâ€™t Work']\n",
      "\n",
      "Users similar to: Maro\n",
      "[0.6058409214019775, 'https://news.ycombinator.com/user?id=jiggunjer', 'jiggunjer']\n",
      "[0.5862621068954468, 'https://news.ycombinator.com/user?id=xtrapolate', 'xtrapolate']\n",
      "[0.5581708550453186, 'https://news.ycombinator.com/user?id=ebcode', 'ebcode']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_post_vector(post_id):\n",
    "    return model.embedding.weight[post_lookup[post_id]]\n",
    "\n",
    "def similar_posts_by_title(title):\n",
    "    post_id = title_to_id[title]\n",
    "    pv = get_post_vector(post_id)\n",
    "    dists = []\n",
    "    for other_post in posts:\n",
    "        if other_post == post_id: continue\n",
    "        ov = get_post_vector(other_post)\n",
    "        dist = torch.dot(pv, ov)\n",
    "        dists.append([float(dist), 'https://news.ycombinator.com/item?id=' + other_post, id_to_title[other_post]])\n",
    "    similars = sorted(dists)[-3:]\n",
    "    similars.reverse()\n",
    "    return similars\n",
    "\n",
    "def get_user_vector(user):\n",
    "    return model.embedding.weight[user_lookup[user]]\n",
    "\n",
    "def similar_users_by_name(user):\n",
    "    uv = get_user_vector(user)\n",
    "    dists = []\n",
    "    for other_user in users:\n",
    "        if other_user == user: continue\n",
    "        ov = get_user_vector(other_user)\n",
    "        dist = torch.dot(uv, ov)\n",
    "        dists.append([float(dist), 'https://news.ycombinator.com/user?id=' + other_user, other_user])\n",
    "    similars = sorted(dists)[-3:]\n",
    "    similars.reverse()\n",
    "    return similars  \n",
    "\n",
    "def posts_recommended_for_user(user):\n",
    "    uv = get_user_vector(user)\n",
    "    dists = []\n",
    "    for post in posts:\n",
    "        if post_lookup[post] in idx_user_posts[user_lookup[user]]: continue\n",
    "        pv = get_post_vector(post)\n",
    "        dist = torch.dot(uv, pv)\n",
    "        dists.append([float(dist), 'https://news.ycombinator.com/item?id=' + post, id_to_title[post]])\n",
    "    similars = sorted(dists)[-10:]\n",
    "    similars.reverse()\n",
    "    return similars  \n",
    "\n",
    "test_posts = [\n",
    "    \"\"\"Self-driving Uber car kills Arizona woman crossing street\"\"\",\n",
    "    \"\"\"Ask HN: Who is hiring? (May 2018)\"\"\",\n",
    "    \"\"\"Conversations with a six-year-old on functional programming\"\"\",\n",
    "    \"\"\"You probably don't need AI/ML. You can make do with well written SQL scripts\"\"\",\n",
    "    \"\"\"Bitcoin has little shot at ever being a major global currency\"\"\",\n",
    "    \"\"\"2018 MacBook Pro Review\"\"\",\n",
    "]\n",
    "\n",
    "for post_title in test_posts:\n",
    "    print('Posts similar to: ' + post_title)\n",
    "    similars = similar_posts_by_title(post_title)\n",
    "    for s in similars:\n",
    "        print(s)\n",
    "    print()\n",
    "\n",
    "user = 'Maro'\n",
    "print('Posts recommended for: ' + user)\n",
    "similars = posts_recommended_for_user(user)\n",
    "for s in similars:\n",
    "    print(s)\n",
    "print()    \n",
    "\n",
    "user = 'Maro'\n",
    "print('Users similar to: ' + user)\n",
    "similars = similar_users_by_name(user)\n",
    "for s in similars:\n",
    "    print(s)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
